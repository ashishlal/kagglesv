{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/xhlulu/severstal-steel-predict-missing-masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50272, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train.csv.zip')\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7204, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId EncodedPixels\n",
       "0  004f40c73.jpg_1           1 1\n",
       "1  004f40c73.jpg_2           1 1\n",
       "2  004f40c73.jpg_3           1 1\n",
       "3  004f40c73.jpg_4           1 1\n",
       "4  006f39c41.jpg_1           1 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('../data/sample_submission.csv')\n",
    "print(submission_df.shape)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['004f40c73.jpg', '006f39c41.jpg', '00b7fb703.jpg', ...,\n",
       "       'ffbf79783.jpg', 'ffc9a6187.jpg', 'ffdb60677.jpg'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_test_images = submission_df['ImageId_ClassId'].apply(\n",
    "    lambda x: x.split('_')[0]\n",
    ").unique()\n",
    "\n",
    "unique_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>isNan</th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>False</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>00031f466.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels  isNan  \\\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...  False   \n",
       "1  0002cc93b.jpg_2                                                NaN   True   \n",
       "2  0002cc93b.jpg_3                                                NaN   True   \n",
       "3  0002cc93b.jpg_4                                                NaN   True   \n",
       "4  00031f466.jpg_1                                                NaN   True   \n",
       "\n",
       "         ImageId  \n",
       "0  0002cc93b.jpg  \n",
       "1  0002cc93b.jpg  \n",
       "2  0002cc93b.jpg  \n",
       "3  0002cc93b.jpg  \n",
       "4  00031f466.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['isNan'] = pd.isna(train_df['EncodedPixels'])\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(\n",
    "    lambda x: x.split('_')[0]\n",
    ")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>missingCount</th>\n",
       "      <th>allMissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000418bfc.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000789191.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  missingCount  allMissing\n",
       "0  0002cc93b.jpg             3           0\n",
       "1  00031f466.jpg             4           1\n",
       "2  000418bfc.jpg             4           1\n",
       "3  000789191.jpg             4           1\n",
       "4  0007a71bf.jpg             3           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nan_df = train_df.groupby(by='ImageId', axis=0).agg('sum')\n",
    "train_nan_df.reset_index(inplace=True)\n",
    "train_nan_df.rename(columns={'isNan': 'missingCount'}, inplace=True)\n",
    "train_nan_df['missingCount'] = train_nan_df['missingCount'].astype(np.int32)\n",
    "train_nan_df['allMissing'] = (train_nan_df['missingCount'] == 4).astype(int)\n",
    "\n",
    "train_nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1801, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f40c73.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006f39c41.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00b7fb703.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00bbcd9af.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0108ce457.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId\n",
       "0  004f40c73.jpg\n",
       "1  006f39c41.jpg\n",
       "2  00b7fb703.jpg\n",
       "3  00bbcd9af.jpg\n",
       "4  0108ce457.jpg"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nan_df = pd.DataFrame(unique_test_images, columns=['ImageId'])\n",
    "print(test_nan_df.shape)\n",
    "test_nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6239\n",
       "4    5902\n",
       "2     425\n",
       "1       2\n",
       "Name: missingCount, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nan_df['missingCount'].hist()\n",
    "train_nan_df['missingCount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(code, base, resize=True):\n",
    "    path = f'{base}/{code}'\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def validate_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12568/12568 [01:16<00:00, 163.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = '../cache/train'\n",
    "validate_path(train_path)\n",
    "\n",
    "for code in tqdm(train_nan_df['ImageId']):\n",
    "    img = load_img(\n",
    "        code,\n",
    "        base='../data/train_images'\n",
    "    )\n",
    "    path = code.replace('.jpg', '')\n",
    "    cv2.imwrite(f'{train_path}/{path}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nan_df['ImageId'] = train_nan_df['ImageId'].apply(\n",
    "    lambda x: x.replace('.jpg', '.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10683 validated image filenames.\n",
      "Found 1885 validated image filenames.\n",
      "Found 1801 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(\n",
    "        zoom_range=0.1,  # set range for random zoom\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='constant',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True,  # randomly flip images,\n",
    "        rescale=1/255.,\n",
    "        validation_split=0.15\n",
    "    )\n",
    "\n",
    "def create_test_gen():\n",
    "    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(\n",
    "        test_nan_df,\n",
    "        directory='../data/test_images/',\n",
    "        x_col='ImageId',\n",
    "        class_mode=None,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "def create_flow(datagen, subset):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        train_nan_df, \n",
    "        directory='../cache/train',\n",
    "        x_col='ImageId', \n",
    "        y_col='allMissing', \n",
    "        class_mode='other',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        subset=subset\n",
    "    )\n",
    "\n",
    "# Using original generator\n",
    "data_generator = create_datagen()\n",
    "train_gen = create_flow(data_generator, 'training')\n",
    "val_gen = create_flow(data_generator, 'validation')\n",
    "test_gen = create_test_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    mobilenet = MobileNetV2(\n",
    "        include_top=False,\n",
    "        input_shape=(224,224,3),\n",
    "        weights = 'imagenet'\n",
    "#         weights=(\n",
    "#             '../input/'\n",
    "#             'mobilenet-v2-keras-weights/'\n",
    "#             'mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n",
    "#         )\n",
    "    )\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(mobilenet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(1e-4),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 09:22:50.579654 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 09:22:50.597258 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 09:22:50.602441 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0804 09:22:50.623836 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0804 09:22:50.624584 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 09:22:50.684159 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 14s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 09:23:14.411942 140090401687360 deprecation.py:506] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 09:23:14.442376 140090401687360 deprecation_wrapper.py:119] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0804 09:23:14.449680 140090401687360 deprecation.py:323] From /home/watts/anaconda3/envs/sv/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 2,259,265\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "167/166 [==============================] - 983s 6s/step - loss: 0.4009 - acc: 0.8045 - val_loss: 0.3673 - val_acc: 0.8414\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.84138, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 2/25\n",
      "167/166 [==============================] - 962s 6s/step - loss: 0.2463 - acc: 0.8938 - val_loss: 0.2577 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.84138 to 0.89973, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 3/25\n",
      "167/166 [==============================] - 963s 6s/step - loss: 0.2026 - acc: 0.9188 - val_loss: 0.2194 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89973 to 0.90981, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 4/25\n",
      "167/166 [==============================] - 966s 6s/step - loss: 0.1756 - acc: 0.9276 - val_loss: 0.1921 - val_acc: 0.9183\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.90981 to 0.91830, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 5/25\n",
      "167/166 [==============================] - 962s 6s/step - loss: 0.1549 - acc: 0.9373 - val_loss: 0.1695 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91830 to 0.92838, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 6/25\n",
      "167/166 [==============================] - 965s 6s/step - loss: 0.1379 - acc: 0.9455 - val_loss: 0.2350 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92838\n",
      "Epoch 7/25\n",
      "167/166 [==============================] - 962s 6s/step - loss: 0.1241 - acc: 0.9518 - val_loss: 0.2097 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92838\n",
      "Epoch 8/25\n",
      "167/166 [==============================] - 959s 6s/step - loss: 0.1179 - acc: 0.9528 - val_loss: 0.1838 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92838 to 0.92838, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 9/25\n",
      "167/166 [==============================] - 960s 6s/step - loss: 0.1070 - acc: 0.9582 - val_loss: 0.2061 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92838\n",
      "Epoch 10/25\n",
      "167/166 [==============================] - 959s 6s/step - loss: 0.0996 - acc: 0.9590 - val_loss: 0.1709 - val_acc: 0.9353\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92838 to 0.93528, saving model to ../cache/mobilenetv2_model.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 11/25\n",
      "167/166 [==============================] - 963s 6s/step - loss: 0.0888 - acc: 0.9649 - val_loss: 0.1408 - val_acc: 0.9438\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93528 to 0.94377, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 12/25\n",
      "167/166 [==============================] - 964s 6s/step - loss: 0.0786 - acc: 0.9686 - val_loss: 0.1304 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.94377 to 0.95066, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 13/25\n",
      "167/166 [==============================] - 965s 6s/step - loss: 0.0785 - acc: 0.9707 - val_loss: 0.1278 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.95066 to 0.95279, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 14/25\n",
      "167/166 [==============================] - 966s 6s/step - loss: 0.0751 - acc: 0.9698 - val_loss: 0.1230 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.95279 to 0.95279, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 15/25\n",
      "167/166 [==============================] - 967s 6s/step - loss: 0.0707 - acc: 0.9717 - val_loss: 0.1262 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.95279 to 0.95756, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 16/25\n",
      "167/166 [==============================] - 966s 6s/step - loss: 0.0675 - acc: 0.9734 - val_loss: 0.1178 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.95756 to 0.96021, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 17/25\n",
      "167/166 [==============================] - 967s 6s/step - loss: 0.0663 - acc: 0.9746 - val_loss: 0.1261 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96021\n",
      "Epoch 18/25\n",
      "167/166 [==============================] - 999s 6s/step - loss: 0.0666 - acc: 0.9755 - val_loss: 0.1282 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96021\n",
      "Epoch 19/25\n",
      "167/166 [==============================] - 1010s 6s/step - loss: 0.0649 - acc: 0.9747 - val_loss: 0.1214 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.96021\n",
      "Epoch 20/25\n",
      "167/166 [==============================] - 1014s 6s/step - loss: 0.0620 - acc: 0.9765 - val_loss: 0.1275 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96021\n",
      "Epoch 21/25\n",
      "167/166 [==============================] - 1011s 6s/step - loss: 0.0648 - acc: 0.9743 - val_loss: 0.1294 - val_acc: 0.9565\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.96021\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 22/25\n",
      "167/166 [==============================] - 1009s 6s/step - loss: 0.0621 - acc: 0.9749 - val_loss: 0.1205 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.96021\n",
      "Epoch 23/25\n",
      "167/166 [==============================] - 1009s 6s/step - loss: 0.0619 - acc: 0.9762 - val_loss: 0.1216 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.96021 to 0.96127, saving model to ../cache/mobilenetv2_model.h5\n",
      "Epoch 24/25\n",
      "167/166 [==============================] - 1013s 6s/step - loss: 0.0593 - acc: 0.9778 - val_loss: 0.1355 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.96127\n",
      "Epoch 25/25\n",
      "167/166 [==============================] - 1013s 6s/step - loss: 0.0623 - acc: 0.9755 - val_loss: 0.1301 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.96127\n"
     ]
    }
   ],
   "source": [
    "total_steps = train_nan_df.shape[0] / BATCH_SIZE\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    '../cache/mobilenetv2_model.h5', \n",
    "    monitor='val_acc', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=total_steps * 0.85,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=total_steps * 0.15,\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
