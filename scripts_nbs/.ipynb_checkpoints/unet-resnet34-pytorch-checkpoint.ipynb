{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, CLAHE, HueSaturationValue, VerticalFlip, IAASharpen,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n",
    "    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n",
    "    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n",
    "    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    \n",
    "    masks = np.zeros((256, 1600, 5), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "#     print(labels)\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "#     mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "#     masks[:,:,4] = mask.reshape(256, 1600, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "#         print(img.shape, mask.shape)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "#         print(img.shape)\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "#         print(mask.shape)\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [\n",
    "                HorizontalFlip(p=0.25), # only horizontal flip as of now\n",
    "                VerticalFlip(p=0.25),\n",
    "                OneOf([\n",
    "                    RandomBrightness(),\n",
    "                    IAASharpen(),\n",
    "#                     ElasticTransform(alpha=50, sigma=5),\n",
    "                ], p=0.3)\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "    df['ClassId'] = df['ClassId'].astype(int)\n",
    "    df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = SteelDataset(df, data_folder, mean, std, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds\n",
    "\n",
    "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        dice = dice.mean().item()\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.base_dice_scores = []\n",
    "        self.dice_neg_scores = []\n",
    "        self.dice_pos_scores = []\n",
    "        self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
    "        self.base_dice_scores.append(dice)\n",
    "        self.dice_pos_scores.append(dice_pos)\n",
    "        self.dice_neg_scores.append(dice_neg)\n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        dice = np.mean(self.base_dice_scores)\n",
    "        dice_neg = np.mean(self.dice_neg_scores)\n",
    "        dice_pos = np.mean(self.dice_pos_scores)\n",
    "        dices = [dice, dice_neg, dice_pos]\n",
    "        iou = np.nanmean(self.iou_scores)\n",
    "        return dices, iou\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    dices, iou = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(\"Loss: %0.4f | IoU: %0.4f | dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f\" % (epoch_loss, iou, dice, dice_neg, dice_pos))\n",
    "    return dice, iou\n",
    "\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
    "    '''computes iou for one ground truth mask and predicted mask'''\n",
    "    pred[label == ignore_index] = 0\n",
    "    ious = []\n",
    "    for c in classes:\n",
    "        label_c = label == c\n",
    "        if only_present and np.sum(label_c) == 0:\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum()\n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union)\n",
    "    return ious if ious else [1]\n",
    "\n",
    "def compute_iou_batch(outputs, labels, classes=None):\n",
    "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
    "    ious = []\n",
    "    preds = np.copy(outputs) # copy is imp\n",
    "    labels = np.array(labels) # tensor to np\n",
    "    for pred, label in zip(preds, labels):\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RGB_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_RGB_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "CONVERSION_34=[\n",
    " 'block0.0.weight',     (64, 3, 7, 7),   'conv1.weight',        (64, 3, 7, 7),\n",
    " 'block0.1.weight',     (64,),   'bn1.weight',  (64,),\n",
    " 'block0.1.bias',       (64,),   'bn1.bias',    (64,),\n",
    " 'block0.1.running_mean',       (64,),   'bn1.running_mean',    (64,),\n",
    " 'block0.1.running_var',        (64,),   'bn1.running_var',     (64,),\n",
    " 'block1.1.conv_bn1.conv.weight',       (64, 64, 3, 3),  'layer1.0.conv1.weight',       (64, 64, 3, 3),\n",
    " 'block1.1.conv_bn1.bn.weight', (64,),   'layer1.0.bn1.weight', (64,),\n",
    " 'block1.1.conv_bn1.bn.bias',   (64,),   'layer1.0.bn1.bias',   (64,),\n",
    " 'block1.1.conv_bn1.bn.running_mean',   (64,),   'layer1.0.bn1.running_mean',   (64,),\n",
    " 'block1.1.conv_bn1.bn.running_var',    (64,),   'layer1.0.bn1.running_var',    (64,),\n",
    " 'block1.1.conv_bn2.conv.weight',       (64, 64, 3, 3),  'layer1.0.conv2.weight',       (64, 64, 3, 3),\n",
    " 'block1.1.conv_bn2.bn.weight', (64,),   'layer1.0.bn2.weight', (64,),\n",
    " 'block1.1.conv_bn2.bn.bias',   (64,),   'layer1.0.bn2.bias',   (64,),\n",
    " 'block1.1.conv_bn2.bn.running_mean',   (64,),   'layer1.0.bn2.running_mean',   (64,),\n",
    " 'block1.1.conv_bn2.bn.running_var',    (64,),   'layer1.0.bn2.running_var',    (64,),\n",
    " 'block1.2.conv_bn1.conv.weight',       (64, 64, 3, 3),  'layer1.1.conv1.weight',       (64, 64, 3, 3),\n",
    " 'block1.2.conv_bn1.bn.weight', (64,),   'layer1.1.bn1.weight', (64,),\n",
    " 'block1.2.conv_bn1.bn.bias',   (64,),   'layer1.1.bn1.bias',   (64,),\n",
    " 'block1.2.conv_bn1.bn.running_mean',   (64,),   'layer1.1.bn1.running_mean',   (64,),\n",
    " 'block1.2.conv_bn1.bn.running_var',    (64,),   'layer1.1.bn1.running_var',    (64,),\n",
    " 'block1.2.conv_bn2.conv.weight',       (64, 64, 3, 3),  'layer1.1.conv2.weight',       (64, 64, 3, 3),\n",
    " 'block1.2.conv_bn2.bn.weight', (64,),   'layer1.1.bn2.weight', (64,),\n",
    " 'block1.2.conv_bn2.bn.bias',   (64,),   'layer1.1.bn2.bias',   (64,),\n",
    " 'block1.2.conv_bn2.bn.running_mean',   (64,),   'layer1.1.bn2.running_mean',   (64,),\n",
    " 'block1.2.conv_bn2.bn.running_var',    (64,),   'layer1.1.bn2.running_var',    (64,),\n",
    " 'block1.3.conv_bn1.conv.weight',       (64, 64, 3, 3),  'layer1.2.conv1.weight',       (64, 64, 3, 3),\n",
    " 'block1.3.conv_bn1.bn.weight', (64,),   'layer1.2.bn1.weight', (64,),\n",
    " 'block1.3.conv_bn1.bn.bias',   (64,),   'layer1.2.bn1.bias',   (64,),\n",
    " 'block1.3.conv_bn1.bn.running_mean',   (64,),   'layer1.2.bn1.running_mean',   (64,),\n",
    " 'block1.3.conv_bn1.bn.running_var',    (64,),   'layer1.2.bn1.running_var',    (64,),\n",
    " 'block1.3.conv_bn2.conv.weight',       (64, 64, 3, 3),  'layer1.2.conv2.weight',       (64, 64, 3, 3),\n",
    " 'block1.3.conv_bn2.bn.weight', (64,),   'layer1.2.bn2.weight', (64,),\n",
    " 'block1.3.conv_bn2.bn.bias',   (64,),   'layer1.2.bn2.bias',   (64,),\n",
    " 'block1.3.conv_bn2.bn.running_mean',   (64,),   'layer1.2.bn2.running_mean',   (64,),\n",
    " 'block1.3.conv_bn2.bn.running_var',    (64,),   'layer1.2.bn2.running_var',    (64,),\n",
    "\n",
    " 'block2.0.conv_bn1.conv.weight',       (128, 64, 3, 3),         'layer2.0.conv1.weight',       (128, 64, 3, 3),\n",
    " 'block2.0.conv_bn1.bn.weight', (128,),  'layer2.0.bn1.weight', (128,),\n",
    " 'block2.0.conv_bn1.bn.bias',   (128,),  'layer2.0.bn1.bias',   (128,),\n",
    " 'block2.0.conv_bn1.bn.running_mean',   (128,),  'layer2.0.bn1.running_mean',   (128,),\n",
    " 'block2.0.conv_bn1.bn.running_var',    (128,),  'layer2.0.bn1.running_var',    (128,),\n",
    " 'block2.0.conv_bn2.conv.weight',       (128, 128, 3, 3),        'layer2.0.conv2.weight',       (128, 128, 3, 3),\n",
    " 'block2.0.conv_bn2.bn.weight', (128,),  'layer2.0.bn2.weight', (128,),\n",
    " 'block2.0.conv_bn2.bn.bias',   (128,),  'layer2.0.bn2.bias',   (128,),\n",
    " 'block2.0.conv_bn2.bn.running_mean',   (128,),  'layer2.0.bn2.running_mean',   (128,),\n",
    " 'block2.0.conv_bn2.bn.running_var',    (128,),  'layer2.0.bn2.running_var',    (128,),\n",
    " 'block2.0.shortcut.conv.weight',       (128, 64, 1, 1),         'layer2.0.downsample.0.weight',        (128, 64, 1, 1),\n",
    " 'block2.0.shortcut.bn.weight', (128,),  'layer2.0.downsample.1.weight',        (128,),\n",
    " 'block2.0.shortcut.bn.bias',   (128,),  'layer2.0.downsample.1.bias',  (128,),\n",
    " 'block2.0.shortcut.bn.running_mean',   (128,),  'layer2.0.downsample.1.running_mean',  (128,),\n",
    " 'block2.0.shortcut.bn.running_var',    (128,),  'layer2.0.downsample.1.running_var',   (128,),\n",
    " 'block2.1.conv_bn1.conv.weight',       (128, 128, 3, 3),        'layer2.1.conv1.weight',       (128, 128, 3, 3),\n",
    " 'block2.1.conv_bn1.bn.weight', (128,),  'layer2.1.bn1.weight', (128,),\n",
    " 'block2.1.conv_bn1.bn.bias',   (128,),  'layer2.1.bn1.bias',   (128,),\n",
    " 'block2.1.conv_bn1.bn.running_mean',   (128,),  'layer2.1.bn1.running_mean',   (128,),\n",
    " 'block2.1.conv_bn1.bn.running_var',    (128,),  'layer2.1.bn1.running_var',    (128,),\n",
    " 'block2.1.conv_bn2.conv.weight',       (128, 128, 3, 3),        'layer2.1.conv2.weight',       (128, 128, 3, 3),\n",
    " 'block2.1.conv_bn2.bn.weight', (128,),  'layer2.1.bn2.weight', (128,),\n",
    " 'block2.1.conv_bn2.bn.bias',   (128,),  'layer2.1.bn2.bias',   (128,),\n",
    " 'block2.1.conv_bn2.bn.running_mean',   (128,),  'layer2.1.bn2.running_mean',   (128,),\n",
    " 'block2.1.conv_bn2.bn.running_var',    (128,),  'layer2.1.bn2.running_var',    (128,),\n",
    "\n",
    " 'block2.2.conv_bn1.conv.weight',       (128, 128, 3, 3),        'layer2.2.conv1.weight',       (128, 128, 3, 3),\n",
    " 'block2.2.conv_bn1.bn.weight', (128,),  'layer2.2.bn1.weight', (128,),\n",
    " 'block2.2.conv_bn1.bn.bias',   (128,),  'layer2.2.bn1.bias',   (128,),\n",
    " 'block2.2.conv_bn1.bn.running_mean',   (128,),  'layer2.2.bn1.running_mean',   (128,),\n",
    " 'block2.2.conv_bn1.bn.running_var',    (128,),  'layer2.2.bn1.running_var',    (128,),\n",
    " 'block2.2.conv_bn2.conv.weight',       (128, 128, 3, 3),        'layer2.2.conv2.weight',       (128, 128, 3, 3),\n",
    " 'block2.2.conv_bn2.bn.weight', (128,),  'layer2.2.bn2.weight', (128,),\n",
    " 'block2.2.conv_bn2.bn.bias',   (128,),  'layer2.2.bn2.bias',   (128,),\n",
    " 'block2.2.conv_bn2.bn.running_mean',   (128,),  'layer2.2.bn2.running_mean',   (128,),\n",
    " 'block2.2.conv_bn2.bn.running_var',    (128,),  'layer2.2.bn2.running_var',    (128,),\n",
    "\n",
    " 'block2.3.conv_bn1.conv.weight',       (128, 128, 3, 3),        'layer2.3.conv1.weight',       (128, 128, 3, 3),\n",
    " 'block2.3.conv_bn1.bn.weight', (128,),  'layer2.3.bn1.weight', (128,),\n",
    " 'block2.3.conv_bn1.bn.bias',   (128,),  'layer2.3.bn1.bias',   (128,),\n",
    " 'block2.3.conv_bn1.bn.running_mean',   (128,),  'layer2.3.bn1.running_mean',   (128,),\n",
    " 'block2.3.conv_bn1.bn.running_var',    (128,),  'layer2.3.bn1.running_var',    (128,),\n",
    " 'block2.3.conv_bn2.conv.weight',       (128, 128, 3, 3),        'layer2.3.conv2.weight',       (128, 128, 3, 3),\n",
    " 'block2.3.conv_bn2.bn.weight', (128,),  'layer2.3.bn2.weight', (128,),\n",
    " 'block2.3.conv_bn2.bn.bias',   (128,),  'layer2.3.bn2.bias',   (128,),\n",
    " 'block2.3.conv_bn2.bn.running_mean',   (128,),  'layer2.3.bn2.running_mean',   (128,),\n",
    " 'block2.3.conv_bn2.bn.running_var',    (128,),  'layer2.3.bn2.running_var',    (128,),\n",
    "\n",
    "\n",
    " 'block3.0.conv_bn1.conv.weight',       (256, 128, 3, 3),        'layer3.0.conv1.weight',       (256, 128, 3, 3),\n",
    " 'block3.0.conv_bn1.bn.weight', (256,),  'layer3.0.bn1.weight', (256,),\n",
    " 'block3.0.conv_bn1.bn.bias',   (256,),  'layer3.0.bn1.bias',   (256,),\n",
    " 'block3.0.conv_bn1.bn.running_mean',   (256,),  'layer3.0.bn1.running_mean',   (256,),\n",
    " 'block3.0.conv_bn1.bn.running_var',    (256,),  'layer3.0.bn1.running_var',    (256,),\n",
    " 'block3.0.conv_bn2.conv.weight',       (256, 256, 3, 3),        'layer3.0.conv2.weight',       (256, 256, 3, 3),\n",
    " 'block3.0.conv_bn2.bn.weight', (256,),  'layer3.0.bn2.weight', (256,),\n",
    " 'block3.0.conv_bn2.bn.bias',   (256,),  'layer3.0.bn2.bias',   (256,),\n",
    " 'block3.0.conv_bn2.bn.running_mean',   (256,),  'layer3.0.bn2.running_mean',   (256,),\n",
    " 'block3.0.conv_bn2.bn.running_var',    (256,),  'layer3.0.bn2.running_var',    (256,),\n",
    " 'block3.0.shortcut.conv.weight',       (256, 128, 1, 1),        'layer3.0.downsample.0.weight',        (256, 128, 1, 1),\n",
    " 'block3.0.shortcut.bn.weight', (256,),  'layer3.0.downsample.1.weight',        (256,),\n",
    " 'block3.0.shortcut.bn.bias',   (256,),  'layer3.0.downsample.1.bias',  (256,),\n",
    " 'block3.0.shortcut.bn.running_mean',   (256,),  'layer3.0.downsample.1.running_mean',  (256,),\n",
    " 'block3.0.shortcut.bn.running_var',    (256,),  'layer3.0.downsample.1.running_var',   (256,),\n",
    "\n",
    " 'block3.1.conv_bn1.conv.weight',       (256, 256, 3, 3),        'layer3.1.conv1.weight',       (256, 256, 3, 3),\n",
    " 'block3.1.conv_bn1.bn.weight', (256,),  'layer3.1.bn1.weight', (256,),\n",
    " 'block3.1.conv_bn1.bn.bias',   (256,),  'layer3.1.bn1.bias',   (256,),\n",
    " 'block3.1.conv_bn1.bn.running_mean',   (256,),  'layer3.1.bn1.running_mean',   (256,),\n",
    " 'block3.1.conv_bn1.bn.running_var',    (256,),  'layer3.1.bn1.running_var',    (256,),\n",
    " 'block3.1.conv_bn2.conv.weight',       (256, 256, 3, 3),        'layer3.1.conv2.weight',       (256, 256, 3, 3),\n",
    " 'block3.1.conv_bn2.bn.weight', (256,),  'layer3.1.bn2.weight', (256,),\n",
    " 'block3.1.conv_bn2.bn.bias',   (256,),  'layer3.1.bn2.bias',   (256,),\n",
    " 'block3.1.conv_bn2.bn.running_mean',   (256,),  'layer3.1.bn2.running_mean',   (256,),\n",
    " 'block3.1.conv_bn2.bn.running_var',    (256,),  'layer3.1.bn2.running_var',    (256,),\n",
    "\n",
    " 'block3.2.conv_bn1.conv.weight',       (256, 256, 3, 3),        'layer3.2.conv1.weight',       (256, 256, 3, 3),\n",
    " 'block3.2.conv_bn1.bn.weight', (256,),  'layer3.2.bn1.weight', (256,),\n",
    " 'block3.2.conv_bn1.bn.bias',   (256,),  'layer3.2.bn1.bias',   (256,),\n",
    " 'block3.2.conv_bn1.bn.running_mean',   (256,),  'layer3.2.bn1.running_mean',   (256,),\n",
    " 'block3.2.conv_bn1.bn.running_var',    (256,),  'layer3.2.bn1.running_var',    (256,),\n",
    " 'block3.2.conv_bn2.conv.weight',       (256, 256, 3, 3),        'layer3.2.conv2.weight',       (256, 256, 3, 3),\n",
    " 'block3.2.conv_bn2.bn.weight', (256,),  'layer3.2.bn2.weight', (256,),\n",
    " 'block3.2.conv_bn2.bn.bias',   (256,),  'layer3.2.bn2.bias',   (256,),\n",
    " 'block3.2.conv_bn2.bn.running_mean',   (256,),  'layer3.2.bn2.running_mean',   (256,),\n",
    " 'block3.2.conv_bn2.bn.running_var',    (256,),  'layer3.2.bn2.running_var',    (256,),\n",
    "\n",
    " 'block3.3.conv_bn1.conv.weight',       (256, 256, 3, 3),        'layer3.3.conv1.weight',       (256, 256, 3, 3),\n",
    " 'block3.3.conv_bn1.bn.weight', (256,),  'layer3.3.bn1.weight', (256,),\n",
    " 'block3.3.conv_bn1.bn.bias',   (256,),  'layer3.3.bn1.bias',   (256,),\n",
    " 'block3.3.conv_bn1.bn.running_mean',   (256,),  'layer3.3.bn1.running_mean',   (256,),\n",
    " 'block3.3.conv_bn1.bn.running_var',    (256,),  'layer3.3.bn1.running_var',    (256,),\n",
    " 'block3.3.conv_bn2.conv.weight',       (256, 256, 3, 3),        'layer3.3.conv2.weight',       (256, 256, 3, 3),\n",
    " 'block3.3.conv_bn2.bn.weight', (256,),  'layer3.3.bn2.weight', (256,),\n",
    " 'block3.3.conv_bn2.bn.bias',   (256,),  'layer3.3.bn2.bias',   (256,),\n",
    " 'block3.3.conv_bn2.bn.running_mean',   (256,),  'layer3.3.bn2.running_mean',   (256,),\n",
    " 'block3.3.conv_bn2.bn.running_var',    (256,),  'layer3.3.bn2.running_var',    (256,),\n",
    "\n",
    " 'block3.4.conv_bn1.conv.weight',       (256, 256, 3, 3),        'layer3.4.conv1.weight',       (256, 256, 3, 3),\n",
    " 'block3.4.conv_bn1.bn.weight', (256,),  'layer3.4.bn1.weight', (256,),\n",
    " 'block3.4.conv_bn1.bn.bias',   (256,),  'layer3.4.bn1.bias',   (256,),\n",
    " 'block3.4.conv_bn1.bn.running_mean',   (256,),  'layer3.4.bn1.running_mean',   (256,),\n",
    " 'block3.4.conv_bn1.bn.running_var',    (256,),  'layer3.4.bn1.running_var',    (256,),\n",
    " 'block3.4.conv_bn2.conv.weight',       (256, 256, 3, 3),        'layer3.4.conv2.weight',       (256, 256, 3, 3),\n",
    " 'block3.4.conv_bn2.bn.weight', (256,),  'layer3.4.bn2.weight', (256,),\n",
    " 'block3.4.conv_bn2.bn.bias',   (256,),  'layer3.4.bn2.bias',   (256,),\n",
    " 'block3.4.conv_bn2.bn.running_mean',   (256,),  'layer3.4.bn2.running_mean',   (256,),\n",
    " 'block3.4.conv_bn2.bn.running_var',    (256,),  'layer3.4.bn2.running_var',    (256,),\n",
    "\n",
    " 'block3.5.conv_bn1.conv.weight',       (256, 256, 3, 3),        'layer3.5.conv1.weight',       (256, 256, 3, 3),\n",
    " 'block3.5.conv_bn1.bn.weight', (256,),  'layer3.5.bn1.weight', (256,),\n",
    " 'block3.5.conv_bn1.bn.bias',   (256,),  'layer3.5.bn1.bias',   (256,),\n",
    " 'block3.5.conv_bn1.bn.running_mean',   (256,),  'layer3.5.bn1.running_mean',   (256,),\n",
    " 'block3.5.conv_bn1.bn.running_var',    (256,),  'layer3.5.bn1.running_var',    (256,),\n",
    " 'block3.5.conv_bn2.conv.weight',       (256, 256, 3, 3),        'layer3.5.conv2.weight',       (256, 256, 3, 3),\n",
    " 'block3.5.conv_bn2.bn.weight', (256,),  'layer3.5.bn2.weight', (256,),\n",
    " 'block3.5.conv_bn2.bn.bias',   (256,),  'layer3.5.bn2.bias',   (256,),\n",
    " 'block3.5.conv_bn2.bn.running_mean',   (256,),  'layer3.5.bn2.running_mean',   (256,),\n",
    " 'block3.5.conv_bn2.bn.running_var',    (256,),  'layer3.5.bn2.running_var',    (256,),\n",
    "\n",
    " 'block4.0.conv_bn1.conv.weight',       (512, 256, 3, 3),        'layer4.0.conv1.weight',       (512, 256, 3, 3),\n",
    " 'block4.0.conv_bn1.bn.weight', (512,),  'layer4.0.bn1.weight', (512,),\n",
    " 'block4.0.conv_bn1.bn.bias',   (512,),  'layer4.0.bn1.bias',   (512,),\n",
    " 'block4.0.conv_bn1.bn.running_mean',   (512,),  'layer4.0.bn1.running_mean',   (512,),\n",
    " 'block4.0.conv_bn1.bn.running_var',    (512,),  'layer4.0.bn1.running_var',    (512,),\n",
    " 'block4.0.conv_bn2.conv.weight',       (512, 512, 3, 3),        'layer4.0.conv2.weight',       (512, 512, 3, 3),\n",
    " 'block4.0.conv_bn2.bn.weight', (512,),  'layer4.0.bn2.weight', (512,),\n",
    " 'block4.0.conv_bn2.bn.bias',   (512,),  'layer4.0.bn2.bias',   (512,),\n",
    " 'block4.0.conv_bn2.bn.running_mean',   (512,),  'layer4.0.bn2.running_mean',   (512,),\n",
    " 'block4.0.conv_bn2.bn.running_var',    (512,),  'layer4.0.bn2.running_var',    (512,),\n",
    " 'block4.0.shortcut.conv.weight',       (512, 256, 1, 1),        'layer4.0.downsample.0.weight',        (512, 256, 1, 1),\n",
    " 'block4.0.shortcut.bn.weight', (512,),  'layer4.0.downsample.1.weight',        (512,),\n",
    " 'block4.0.shortcut.bn.bias',   (512,),  'layer4.0.downsample.1.bias',  (512,),\n",
    " 'block4.0.shortcut.bn.running_mean',   (512,),  'layer4.0.downsample.1.running_mean',  (512,),\n",
    " 'block4.0.shortcut.bn.running_var',    (512,),  'layer4.0.downsample.1.running_var',   (512,),\n",
    "\n",
    " 'block4.1.conv_bn1.conv.weight',       (512, 512, 3, 3),        'layer4.1.conv1.weight',       (512, 512, 3, 3),\n",
    " 'block4.1.conv_bn1.bn.weight', (512,),  'layer4.1.bn1.weight', (512,),\n",
    " 'block4.1.conv_bn1.bn.bias',   (512,),  'layer4.1.bn1.bias',   (512,),\n",
    " 'block4.1.conv_bn1.bn.running_mean',   (512,),  'layer4.1.bn1.running_mean',   (512,),\n",
    " 'block4.1.conv_bn1.bn.running_var',    (512,),  'layer4.1.bn1.running_var',    (512,),\n",
    " 'block4.1.conv_bn2.conv.weight',       (512, 512, 3, 3),        'layer4.1.conv2.weight',       (512, 512, 3, 3),\n",
    " 'block4.1.conv_bn2.bn.weight', (512,),  'layer4.1.bn2.weight', (512,),\n",
    " 'block4.1.conv_bn2.bn.bias',   (512,),  'layer4.1.bn2.bias',   (512,),\n",
    " 'block4.1.conv_bn2.bn.running_mean',   (512,),  'layer4.1.bn2.running_mean',   (512,),\n",
    " 'block4.1.conv_bn2.bn.running_var',    (512,),  'layer4.1.bn2.running_var',    (512,),\n",
    "\n",
    " 'block4.2.conv_bn1.conv.weight',       (512, 512, 3, 3),        'layer4.2.conv1.weight',       (512, 512, 3, 3),\n",
    " 'block4.2.conv_bn1.bn.weight', (512,),  'layer4.2.bn1.weight', (512,),\n",
    " 'block4.2.conv_bn1.bn.bias',   (512,),  'layer4.2.bn1.bias',   (512,),\n",
    " 'block4.2.conv_bn1.bn.running_mean',   (512,),  'layer4.2.bn1.running_mean',   (512,),\n",
    " 'block4.2.conv_bn1.bn.running_var',    (512,),  'layer4.2.bn1.running_var',    (512,),\n",
    " 'block4.2.conv_bn2.conv.weight',       (512, 512, 3, 3),        'layer4.2.conv2.weight',       (512, 512, 3, 3),\n",
    " 'block4.2.conv_bn2.bn.weight', (512,),  'layer4.2.bn2.weight', (512,),\n",
    " 'block4.2.conv_bn2.bn.bias',   (512,),  'layer4.2.bn2.bias',   (512,),\n",
    " 'block4.2.conv_bn2.bn.running_mean',   (512,),  'layer4.2.bn2.running_mean',   (512,),\n",
    " 'block4.2.conv_bn2.bn.running_var',    (512,),  'layer4.2.bn2.running_var',    (512,),\n",
    "\n",
    " 'logit.weight',        (1000, 512),     'fc.weight',   (1000, 512),\n",
    " 'logit.bias',  (1000,),         'fc.bias',     (1000,),\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN_FILE = '../cache/resnet34-333f7ec4.pth'\n",
    "\n",
    "def load_pretrain(net, skip=[], pretrain_file=PRETRAIN_FILE, conversion=CONVERSION_34, is_print=True):\n",
    "\n",
    "    #raise NotImplementedError\n",
    "    print('\\tload pretrain_file: %s'%pretrain_file)\n",
    "\n",
    "    #pretrain_state_dict = torch.load(pretrain_file)\n",
    "    pretrain_state_dict = torch.load(pretrain_file, map_location=lambda storage, loc: storage)\n",
    "    state_dict = net.state_dict()\n",
    "\n",
    "    i = 0\n",
    "    conversion = np.array(conversion).reshape(-1,4)\n",
    "    for key,_,pretrain_key,_ in conversion:\n",
    "        if any(s in key for s in\n",
    "            ['.num_batches_tracked',]+skip):\n",
    "            continue\n",
    "\n",
    "        #print('\\t\\t',key)\n",
    "        if is_print:\n",
    "            print('\\t\\t','%-48s  %-24s  <---  %-32s  %-24s'%(\n",
    "                key, str(state_dict[key].shape),\n",
    "                pretrain_key, str(pretrain_state_dict[pretrain_key].shape),\n",
    "            ))\n",
    "        i = i+1\n",
    "\n",
    "        state_dict[key] = pretrain_state_dict[pretrain_key]\n",
    "\n",
    "    net.load_state_dict(state_dict)\n",
    "    print('')\n",
    "    print('len(pretrain_state_dict.keys()) = %d'%len(pretrain_state_dict.keys()))\n",
    "    print('len(state_dict.keys())          = %d'%len(state_dict.keys()))\n",
    "    print('loaded    = %d'%i)\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "class ConvBn2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, padding=1, stride=1):\n",
    "        super(ConvBn2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding, stride=stride, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channel, eps=1e-5)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############  resnext50 pyramid feature net #######################################\n",
    "# https://github.com/Hsuxu/ResNeXt/blob/master/models.py\n",
    "# https://github.com/D-X-Y/ResNeXt-DenseNet/blob/master/models/resnext.py\n",
    "# https://github.com/miraclewkf/ResNeXt-PyTorch/blob/master/resnext.py\n",
    "\n",
    "\n",
    "# bottleneck type C\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channel, channel, out_channel, stride=1, is_shortcut=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.is_shortcut = is_shortcut\n",
    "\n",
    "        self.conv_bn1 = ConvBn2d(in_channel,    channel, kernel_size=3, padding=1, stride=stride)\n",
    "        self.conv_bn2 = ConvBn2d(   channel,out_channel, kernel_size=3, padding=1, stride=1)\n",
    "\n",
    "        if is_shortcut:\n",
    "            self.shortcut = ConvBn2d(in_channel, out_channel, kernel_size=1, padding=0, stride=stride)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = F.relu(self.conv_bn1(x),inplace=True)\n",
    "        z = self.conv_bn2(z)\n",
    "\n",
    "        if self.is_shortcut:\n",
    "            x = self.shortcut(x)\n",
    "\n",
    "        z += x\n",
    "        z = F.relu(z,inplace=True)\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet34\n",
    "class ResNet34(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class=1000 ):\n",
    "        super(ResNet34, self).__init__()\n",
    "\n",
    "\n",
    "        self.block0  = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, padding=3, stride=2, bias=False),\n",
    "            BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.block1  = nn.Sequential(\n",
    "             nn.MaxPool2d(kernel_size=3, padding=1, stride=2),\n",
    "             BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,),\n",
    "          * [BasicBlock( 64, 64, 64, stride=1, is_shortcut=False,) for i in range(1,3)],\n",
    "        )\n",
    "        self.block2  = nn.Sequential(\n",
    "             BasicBlock( 64,128,128, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(128,128,128, stride=1, is_shortcut=False,) for i in range(1,4)],\n",
    "        )\n",
    "        self.block3  = nn.Sequential(\n",
    "             BasicBlock(128,256,256, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(256,256,256, stride=1, is_shortcut=False,) for i in range(1,6)],\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "             BasicBlock(256,512,512, stride=2, is_shortcut=True, ),\n",
    "          * [BasicBlock(512,512,512, stride=1, is_shortcut=False,) for i in range(1,3)],\n",
    "        )\n",
    "        self.logit = nn.Linear(512,num_class)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = len(x)\n",
    "\n",
    "        x = self.block0(x)\n",
    "        x = F.max_pool2d(x,kernel_size=3, padding=1, stride=2, ceil_mode=False)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        logit = self.logit(x)\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsize(x,scale_factor=2):\n",
    "    #x = F.interpolate(x, size=e.shape[2:], mode='nearest')\n",
    "    x = F.interpolate(x, scale_factor=scale_factor, mode='nearest')\n",
    "    return x\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class Decode(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Decode, self).__init__()\n",
    "\n",
    "        self.top = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel//2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            BatchNorm2d( out_channel//2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(out_channel//2, out_channel//2, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            BatchNorm2d(out_channel//2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(0.1),\n",
    "\n",
    "            nn.Conv2d(out_channel//2, out_channel, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True), #Swish(), #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.top(torch.cat(x, 1))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchNorm2d = nn.BatchNorm2d\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def load_pretrain(self, skip, is_print=True):\n",
    "        conversion=copy.copy(CONVERSION_34)\n",
    "        for i in range(0,len(conversion)-8,4):\n",
    "            conversion[i] = 'block.' + conversion[i][5:]\n",
    "        load_pretrain(self, skip, pretrain_file=PRETRAIN_FILE, conversion=conversion, is_print=is_print)\n",
    "\n",
    "    def __init__(self, num_class=5, drop_connect_rate=0.2):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        e = ResNet34()\n",
    "        self.block = nn.ModuleList([\n",
    "           e.block0,\n",
    "           e.block1,\n",
    "           e.block2,\n",
    "           e.block3,\n",
    "           e.block4\n",
    "        ])\n",
    "        e = None  #dropped\n",
    "\n",
    "        self.decode1 =  Decode(512,     128)\n",
    "        self.decode2 =  Decode(128+256, 128)\n",
    "        self.decode3 =  Decode(128+128, 128)\n",
    "        self.decode4 =  Decode(128+ 64, 128)\n",
    "        self.decode5 =  Decode(128+ 64, 128)\n",
    "        self.logit = nn.Conv2d(128,num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size,C,H,W = x.shape\n",
    "\n",
    "        #----------------------------------\n",
    "        backbone = []\n",
    "        for i in range( len(self.block)):\n",
    "            x = self.block[i](x)\n",
    "            #print(i, x.shape)\n",
    "\n",
    "            if i in [0,1,2,3,4]:\n",
    "                backbone.append(x)\n",
    "\n",
    "        #----------------------------------\n",
    "        x = self.decode1([backbone[-1], ])                   #; print('d1',d1.size())\n",
    "        x = self.decode2([backbone[-2], upsize(x)])          #; print('d2',d2.size())\n",
    "        x = self.decode3([backbone[-3], upsize(x)])          #; print('d3',d3.size())\n",
    "        x = self.decode4([backbone[-4], upsize(x)])          #; print('d4',d4.size())\n",
    "        x = self.decode5([backbone[-5], upsize(x)])          #; print('d5',d5.size())\n",
    "\n",
    "        logit = self.logit(x)\n",
    "        logit = F.interpolate(logit, size=(H,W), mode='bilinear', align_corners=False)\n",
    "        return logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def criterion(logit, truth, weight=None):\n",
    "#     logit = logit.permute(0, 2, 3, 1).contiguous().view(-1, 5)\n",
    "#     truth = truth.permute(0, 2, 3, 1).contiguous().view(-1)\n",
    "\n",
    "#     if weight is not None: weight = torch.FloatTensor([1]+weight).cuda()\n",
    "#     loss = F.cross_entropy(logit, truth, weight=weight, reduction='none')\n",
    "\n",
    "#     loss = loss.mean()\n",
    "#     return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tload pretrain_file: ../cache/resnet34-333f7ec4.pth\n",
      "\n",
      "len(pretrain_state_dict.keys()) = 182\n",
      "len(state_dict.keys())          = 308\n",
      "loaded    = 180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "model = Net()\n",
    "\n",
    "model.load_pretrain(skip=['logit'], is_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 6\n",
    "        self.batch_size = {\"train\": 8, \"val\": 8}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.lr = 3e-4\n",
    "        self.num_epochs = 35\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                df_path=train_df_path,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        masks = targets.to(self.device)\n",
    "        outputs = self.net(images)\n",
    "        loss = self.criterion(outputs, masks)\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "#         tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
    "            images, targets = batch\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        self.iou_scores[phase].append(iou)\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, \"./model.pth\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '../data/sample_submission.csv'\n",
    "train_df_path = '../data/train.csv'\n",
    "data_folder = \"../data/\"\n",
    "test_data_folder = \"../data/test_images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase: train | ⏰: 23:58:31\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-05f46443fc03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-ca1f2432c288>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             state = {\n\u001b[1;32m     78\u001b[0m                 \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ca1f2432c288>\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, epoch, phase)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# replace `dataloader` with `tk0` for tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-ca1f2432c288>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1646715e70ae>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m#print(i, x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a65a17cf4c5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_bn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_shortcut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a65a17cf4c5d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 * 60/ 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING\n",
    "losses = model_trainer.losses\n",
    "dice_scores = model_trainer.dice_scores # overall dice\n",
    "iou_scores = model_trainer.iou_scores\n",
    "\n",
    "def plot(scores, name):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n",
    "    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n",
    "    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n",
    "    plt.legend(); \n",
    "    plt.show()\n",
    "\n",
    "plot(losses, \"BCE loss\")\n",
    "plot(dice_scores, \"Dice score\")\n",
    "plot(iou_scores, \"IoU score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sv",
   "language": "python",
   "name": "sv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
